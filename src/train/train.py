import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
import gc 
import psutil  
import time
from contextlib import nullcontext
import torch.amp

# ä»æˆ‘ä»¬è‡ªå·±å†™çš„æ–‡ä»¶ä¸­å¯¼å…¥æ¨¡å‹å’Œæ•°æ®é›†ç±»
from unet import create_model, get_model_info
from dataset import SolderDataset
from augmentation import get_augmentation
from model_configs import get_config, list_all_configs
from PIL import Image
import glob

# --- 1. é…ç½®è®­ç»ƒå‚æ•° ---
torch.backends.cudnn.benchmark = True  # å·ç§¯åŠ é€Ÿ

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LEARNING_RATE = 1e-4
BATCH_SIZE = 4 # å¦‚æœä½ çš„æ˜¾å­˜ä¸å¤Ÿï¼Œå¯ä»¥è°ƒå°è¿™ä¸ªå€¼ï¼Œæ¯”å¦‚2æˆ–1
EPOCHS = 20 # è®­ç»ƒè½®æ¬¡ï¼Œå…ˆç”¨ä¸€ä¸ªè¾ƒå°çš„å€¼è·‘é€š
IMG_DIR = './data/dataset_0706/processed' # ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
JSON_DIR = './data/dataset_0706/json' # ä½ çš„JSONæ–‡ä»¶å¤¹è·¯å¾„
MODEL_SAVE_PATH = './models/trained/unet_solder_model.pth' # è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜è·¯å¾„

# æ•°æ®å¢å¼ºé…ç½®
AUGMENTATION_STRATEGY = 'custom'  # å¯é€‰: 'none', 'light', 'medium', 'heavy', 'custom'

# æ¨¡å‹é…ç½®æ–¹å¼1: ä½¿ç”¨é¢„å®šä¹‰é…ç½®ï¼ˆæ¨èï¼‰
MODEL_CONFIG = 'pcb_optimized'  # å¯é€‰: 'basic', 'recommended', 'pcb_optimized', 'high_performance', 'efficient', 'lightweight', 'modern'

# æ¨¡å‹é…ç½®æ–¹å¼2: æ‰‹åŠ¨æŒ‡å®šï¼ˆå¦‚æœä¸ä½¿ç”¨é¢„å®šä¹‰é…ç½®ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„è¡Œï¼‰
# MODEL_NAME = 'unet'              # å¯é€‰: 'unet', 'unetplusplus', 'deeplabv3', 'deeplabv3plus', 'fpn', 'pspnet', 'linknet'
# ENCODER_NAME = 'resnet34'        # å¯é€‰: 'resnet18', 'resnet34', 'resnet50', 'efficientnet-b0', etc.
# ENCODER_WEIGHTS = 'imagenet'     # å¯é€‰: 'imagenet', None (Noneè¡¨ç¤ºéšæœºåˆå§‹åŒ–)

# å®šä¹‰ç±»åˆ«å’Œæ˜ å°„ã€‚è¿™ä¸ªå¿…é¡»å’Œdataset.pyä»¥åŠä½ çš„æ•°æ®ä¿æŒä¸€è‡´
# æ³¨æ„ï¼šç±»åˆ«0é€šå¸¸ç•™ç»™èƒŒæ™¯ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç‰©ä½“ä»1å¼€å§‹
CLASS_MAPPING = {
    'background': 0,
    'good': 1,
    'insufficient': 2,
    'excess': 3,
    'shift': 4,
    'miss': 5,
    # --- æ·»åŠ ä½ æ‰€æœ‰çš„ç±»åˆ« ---
}
NUM_CLASSES = len(CLASS_MAPPING)


def train_fn(loader, model, optimizer, loss_fn, scaler=None):
    """ä¸€è½®è®­ç»ƒçš„é€»è¾‘ï¼Œæ”¯æŒAMPæ··åˆç²¾åº¦"""
    model.train() 
    loop = tqdm(loader, desc="Training")
    total_loss = 0
    for batch_idx, (data, targets) in enumerate(loop):
        data = data.to(device=DEVICE, non_blocking=True)
        targets = targets.to(device=DEVICE, non_blocking=True)
        optimizer.zero_grad()
        # æ”¯æŒAMP
        context = torch.amp.autocast('cuda') if scaler is not None else nullcontext()
        with context:
            predictions = model(data)
            loss = loss_fn(predictions, targets)
        if scaler is not None:
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            optimizer.step()
        total_loss += loss.item()
        loop.set_postfix(loss=loss.item())
        del data, targets, predictions, loss
        if batch_idx % 10 == 0 and torch.cuda.is_available():
            torch.cuda.empty_cache()
    return total_loss / len(loader)

def validate_fn(loader, model, loss_fn, scaler=None):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        loop = tqdm(loader, desc="Validation")
        for batch_idx, (data, targets) in enumerate(loop):
            data = data.to(device=DEVICE, non_blocking=True)
            targets = targets.to(device=DEVICE, non_blocking=True)
            context = torch.amp.autocast('cuda') if scaler is not None else nullcontext()
            with context:
                predictions = model(data)
                loss = loss_fn(predictions, targets)
            total_loss += loss.item()
            del data, targets, predictions, loss
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    return total_loss / len(loader)

# --- æ·»åŠ å†…å­˜ç›‘æ§åŠŸèƒ½ ---
def print_memory_usage():
    """æ‰“å°å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        print(f"GPUå†…å­˜å·²åˆ†é…: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        print(f"GPUå†…å­˜å·²ç¼“å­˜: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
    else:
        process = psutil.Process()
        mem_info = process.memory_info()
        print(f"CPUå†…å­˜ä½¿ç”¨: {mem_info.rss / 1024**3:.2f} GB")

def print_gpu_utilization():
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)} | å·²åˆ†é…: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB | å·²ç¼“å­˜: {torch.cuda.memory_reserved(i)/1024**3:.2f} GB")

def main():
    print(f"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    if torch.cuda.is_available():
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join(str(i) for i in range(torch.cuda.device_count()))
        print(f"æ£€æµ‹åˆ° {torch.cuda.device_count()} å—GPU: {[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]}")
    # è·å–æ¨¡å‹é…ç½®
    if 'MODEL_CONFIG' in globals(): 
        # ä½¿ç”¨é¢„å®šä¹‰é…ç½®
        config = get_config(MODEL_CONFIG)
        model_name = config['model_name']
        encoder_name = config['encoder_name']
        encoder_weights = config['encoder_weights']
        print(f"\nğŸ“‹ ä½¿ç”¨é¢„å®šä¹‰é…ç½®: {MODEL_CONFIG}")
        print(f"   æè¿°: {config['description']}")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    model_info = get_model_info()
    print(f"\nğŸ—ï¸ æ¨¡å‹é…ç½®:")
    print(f"  æ¶æ„: {model_name}")
    print(f"  ç¼–ç å™¨: {encoder_name}")
    print(f"  é¢„è®­ç»ƒæƒé‡: {encoder_weights}")
    print(f"  å¯ç”¨æ¶æ„: {', '.join(model_info['models'][:5])}...")
    print(f"  æ¨èç¼–ç å™¨: {', '.join(model_info['encoders'][:5])}...")

    # 1. åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    # è·å–è®­ç»ƒé›†ä¸­ç¬¬ä¸€å¼ å›¾ç‰‡çš„å°ºå¯¸
    first_image_path = glob.glob(os.path.join(IMG_DIR, "*.jpg"))[0]  # å‡è®¾å›¾ç‰‡ä¸ºjpgæ ¼å¼
    with Image.open(first_image_path) as img:
        width, height = img.size
    print(f"æ ·æœ¬å›¾ç‰‡å°ºå¯¸: {width}x{height}")

    # å…ˆåˆå§‹åŒ–ä¸å¸¦transformçš„æ•°æ®é›†ï¼ˆä»…customå¢å¼ºéœ€è¦datasetï¼‰
    train_dataset_plain = SolderDataset(
        image_dir=IMG_DIR,
        json_dir=JSON_DIR,
        class_mapping={k: v for k, v in CLASS_MAPPING.items() if k != 'background'},
        transform=None,
        use_augmentation=False
    )
    if AUGMENTATION_STRATEGY == 'custom':
        augmentation_transform = get_augmentation(AUGMENTATION_STRATEGY, height=height, width=width, dataset=train_dataset_plain)
    else:
        augmentation_transform = get_augmentation(AUGMENTATION_STRATEGY, height=height, width=width, dataset=None)
    print(f"ä½¿ç”¨æ•°æ®å¢å¼ºç­–ç•¥: {AUGMENTATION_STRATEGY}")

    # ç”¨å¸¦transformçš„train_datasetè¦†ç›–
    train_dataset = SolderDataset(
        image_dir=IMG_DIR,
        json_dir=JSON_DIR,
        class_mapping={k: v for k, v in CLASS_MAPPING.items() if k != 'background'},
        transform=augmentation_transform,
        use_augmentation=True if augmentation_transform is not None else False
    )
    
    # è‡ªåŠ¨è°ƒæ•´num_workerså’Œpin_memory
    num_cpu_cores = os.cpu_count()
    if torch.cuda.is_available():
        workers = 10 if num_cpu_cores is not None else 2
        pin_memory = True
    else:
        workers = max(2, num_cpu_cores // 2) if num_cpu_cores else 2
        pin_memory = False
    print(f"CPUæ ¸å¿ƒæ•°: {num_cpu_cores}, DataLoaderå°†ä½¿ç”¨ {workers} ä¸ªå·¥ä½œè¿›ç¨‹ã€‚")
    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=workers,
        pin_memory=pin_memory,
        persistent_workers=True,
        drop_last=True
    )
    # 2. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    print(f"\nğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    model = create_model(
        n_channels=3, 
        n_classes=NUM_CLASSES,
        model_name=model_name,
        encoder_name=encoder_name,
        encoder_weights=encoder_weights
    )
    # å¤šGPUæ”¯æŒ
    if torch.cuda.device_count() > 1:
        print(f"ä½¿ç”¨ {torch.cuda.device_count()} å—GPUè¿›è¡ŒDataParallelè®­ç»ƒ")
        model = torch.nn.DataParallel(model)
    model = model.to(DEVICE)
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    loss_fn = nn.CrossEntropyLoss() # å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±ï¼Œæ˜¯åˆ†å‰²ä»»åŠ¡çš„æ ‡å‡†é€‰æ‹©
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
    # AMPæ··åˆç²¾åº¦
    scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None
    # 3. å¼€å§‹è®­ç»ƒå¾ªç¯
    for epoch in range(EPOCHS):
        print(f"\n--- Epoch {epoch+1}/{EPOCHS} ---")
        start_time = time.time()
        avg_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)
        print(f"Epoch {epoch+1} - Average Loss: {avg_loss:.4f}")
        print_memory_usage()
        print_gpu_utilization()
        print(f"Epochè€—æ—¶: {time.time()-start_time:.1f}ç§’")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
    # 4. ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
    print("\nè®­ç»ƒå®Œæˆï¼Œæ­£åœ¨ä¿å­˜æ¨¡å‹...")
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {MODEL_SAVE_PATH}")
    
    # æœ€ç»ˆå†…å­˜æ¸…ç†
    del model, optimizer, loss_fn, train_loader, train_dataset
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()


if __name__ == "__main__":
    main()
